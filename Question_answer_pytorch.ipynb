{"cells":[{"metadata":{"id":"pB7Dbip41gTV","trusted":true},"cell_type":"code","source":"import torch","execution_count":1,"outputs":[]},{"metadata":{"id":"CsgwPinSgNQO","outputId":"87d34d14-d614-4d7b-e22f-9a60e8f5cc96","trusted":true},"cell_type":"code","source":"import numpy as np\ntorch.initial_seed()\ntorch.backends.cudnn.deterministic = True\ntorch.manual_seed(999)","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"<torch._C.Generator at 0x7fdaf0042530>"},"metadata":{}}]},{"metadata":{"id":"U6yDVdOAEZI1","trusted":true},"cell_type":"code","source":"data=[('What is your name?','my name is ravin'),\n      ('Where do you live?','i live in mumbai'),\n      ('how are you?','i am fine'),\n      ('What is your favourite color','pink'),\n      ('how old are you?','i am 27 years old'),\n      ('What is your fathers profession?','he is a teacher'),\n      ('What is your job?','i am an engineer')\n      \n]","execution_count":3,"outputs":[]},{"metadata":{"id":"vJ8ad9op2Fk5","trusted":true},"cell_type":"code","source":"question=[]\nanswer=[]\nfor text in data:\n  question.append(text[0])\n  answer.append(text[1])","execution_count":4,"outputs":[]},{"metadata":{"id":"Nw2yFQXE2LBK","outputId":"9f122a5b-8cfd-4474-f82d-99371ab93313","trusted":true},"cell_type":"code","source":"ques_enc={}\ni=1\nmax_ques=0\nfor q in question:\n   words=q.split(' ')\n   if(len(words)>max_ques):\n     max_ques=len(words)\n   for w in words:\n     if w not in ques_enc:\n       ques_enc[w]=i\n       i+=1\nmax_ques","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"5"},"metadata":{}}]},{"metadata":{"id":"CPDO_tui2WaH","trusted":true},"cell_type":"code","source":"ans_enc={}\ni=1\nmax_ans=0\nfor a in answer:\n   words=a.split(' ')\n   if(len(words)>max_ans):\n     max_ans=len(words)\n   for w in words:\n     if w not in ans_enc:\n       ans_enc[w]=i\n       i+=1","execution_count":6,"outputs":[]},{"metadata":{"id":"9bJyySJC2buF","trusted":true},"cell_type":"code","source":"input_dim=len(ques_enc)\noutput_dim=len(ans_enc)","execution_count":7,"outputs":[]},{"metadata":{"id":"lUOGPvFi2g5g","trusted":true},"cell_type":"code","source":"start='<sos>'\nend='<eos>'\npad='<pad>'","execution_count":8,"outputs":[]},{"metadata":{"id":"LBD7L02g2kOz","trusted":true},"cell_type":"code","source":"enc_ques={}\nenc_ques[start]=0\nenc_ques[pad]=input_dim+1\nenc_ques[end]=input_dim+2","execution_count":9,"outputs":[]},{"metadata":{"id":"hqfe-U8n2rBE","trusted":true},"cell_type":"code","source":"enc_ans={}\nenc_ans[start]=0\nenc_ans[pad]=output_dim+1\nenc_ans[end]=output_dim+2","execution_count":10,"outputs":[]},{"metadata":{"id":"gaqX1ZUS2usw","trusted":true},"cell_type":"code","source":"input_vect_dim=input_dim+3\noutput_vect_dim=output_dim+3\nhidden_dim=input_dim","execution_count":11,"outputs":[]},{"metadata":{"id":"b1kaDhZw2yHa","trusted":true},"cell_type":"code","source":"def generate_seq(text,dim,seq_len,word_code):\n  input_seq=[]\n  print(dim)\n  for q in text:\n    words=q.split(' ')\n    enc=[]\n    vect=np.zeros(dim)\n    if dim==input_vect_dim:\n      vect[enc_ques[start]]=1\n      enc.append(vect)\n    else:\n      vect[enc_ans[start]]=1\n      enc.append(vect)\n    #print(len(words))\n    for i,w in enumerate(words):\n      vect=np.zeros(dim)\n      vect[word_code[w]]=1\n      enc.append(vect)\n    #print('i=',i)\n    #print(i+1,max_ques)\n    for k in range(i+1,seq_len):\n      v=np.zeros(dim)\n      if dim==input_vect_dim:\n        v[enc_ques[pad]]=1\n        enc.append(v)\n      else:\n        v[enc_ans[pad]]=1\n        enc.append(v)\n    vect=np.zeros(dim)\n    if dim==input_vect_dim:\n      vect[enc_ques[end]]=1\n    else:\n      vect[enc_ans[end]]=1\n    enc.append(vect)\n    print(q,enc)\n    input_seq.append(enc)\n  Input_seq=np.array(input_seq)\n  print(Input_seq.shape)\n  return Input_seq","execution_count":12,"outputs":[]},{"metadata":{"id":"Unit6a852-41","outputId":"7986b8d8-4f73-4b21-c74e-e32c696e930c","trusted":true},"cell_type":"code","source":"Input_seq=generate_seq(question,input_vect_dim,max_ques,ques_enc)\nInput=torch.FloatTensor(Input_seq)\nInput.shape","execution_count":13,"outputs":[{"output_type":"stream","text":"20\nWhat is your name? [array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 1.])]\nWhere do you live? [array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 1.])]\nhow are you? [array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 1.])]\nWhat is your favourite color [array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 1.])]\nhow old are you? [array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 1.])]\nWhat is your fathers profession? [array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 1.])]\nWhat is your job? [array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       1., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 1.])]\n(7, 7, 20)\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"torch.Size([7, 7, 20])"},"metadata":{}}]},{"metadata":{"id":"Dv1OYFd13E4c","outputId":"0f7aebb3-5ac6-48a5-c24f-2a1bbfdeaa63","trusted":true},"cell_type":"code","source":"Output_seq=generate_seq(answer,output_vect_dim,max_ans,ans_enc)\nOutput=torch.FloatTensor(Output_seq)\nOutput.shape","execution_count":14,"outputs":[{"output_type":"stream","text":"22\nmy name is ravin [array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 1.])]\ni live in mumbai [array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 1.])]\ni am fine [array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 1.])]\npink [array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 1.])]\ni am 27 years old [array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 1.])]\nhe is a teacher [array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 1.])]\ni am an engineer [array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 1., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 1., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 1.])]\n(7, 7, 22)\n","name":"stdout"},{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"torch.Size([7, 7, 22])"},"metadata":{}}]},{"metadata":{"id":"n4vXYMQ_33gB","trusted":true},"cell_type":"code","source":"import torch.nn as nn\nimport torch\nfrom torch.autograd import Variable\nimport torch.nn.functional as F","execution_count":15,"outputs":[]},{"metadata":{"id":"xz-CU6KM0oV3","trusted":true},"cell_type":"code","source":"class Transliteration_EncoderDecoder(nn.Module):\n    \n    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n        super(Transliteration_EncoderDecoder, self).__init__()\n        \n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        print(output_size)\n        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n        self.decoder_rnn_cell = nn.GRU(output_size,hidden_size)\n        \n        self.h2o = nn.Linear(hidden_size, output_size)\n        self.init_output=torch.zeros(7,1,self.output_size)\n        self.init_output[0,:,0]=1\n        \n        self.verbose = verbose\n        \n    def forward(self, input):\n        \n        # encoder\n        #print(output.shape)\n        input=input.view((input.shape[0],1,input.shape[1]))\n        \n        out, hidden = self.encoder_rnn_cell(input)\n        hidden_dec=hidden\n        #print(out.shape,hidden.shape)\n        #print(self.init_output.shape)\n        \n        self.init_output,_=self.decoder_rnn_cell(self.init_output,hidden_dec)\n        #print(self.init_output.shape)\n        target=self.h2o(self.init_output)\n        #print(target)\n        target1=torch.zeros(7,1,self.output_size)\n        for i,t in enumerate(target):\n          if i==0:\n            target1[:,:,i]=1\n          else:\n            target1[i,:,:]=target[i-1,:,:]\n        self.init_output=target1\n        #print('target:',target)\n        #print('target1:',target1)\n        target=target.view((target.shape[0],target.shape[2]))  \n        target=F.log_softmax(target,dim=1) \n        #print(torch.argmax(out_dec,dim=1).shape)\n        #print(torch.argmax(out_dec,dim=1))\n        return target","execution_count":16,"outputs":[]},{"metadata":{"id":"wQ-0STtm5uDl","outputId":"8f8d3dcd-b0eb-458f-fee5-8fcd08aba28e","trusted":true},"cell_type":"code","source":"model= Transliteration_EncoderDecoder(input_vect_dim,hidden_dim,output_vect_dim)","execution_count":17,"outputs":[{"output_type":"stream","text":"22\n","name":"stdout"}]},{"metadata":{"id":"caepCq3v5-3c","outputId":"dc1dc31f-9e1c-4165-bb89-3df8e84ec19e","trusted":true},"cell_type":"code","source":"for i in range(3):\n  print(model(Input[i]))\n  print('---------')","execution_count":18,"outputs":[{"output_type":"stream","text":"tensor([[-2.8678, -3.2539, -3.2127, -3.2476, -3.0657, -3.0034, -3.2067, -3.2117,\n         -2.9446, -2.9457, -3.2194, -3.0515, -3.1038, -3.1218, -3.2247, -3.0005,\n         -2.8723, -3.3176, -3.0391, -3.3255, -3.0425, -2.9351],\n        [-2.9204, -3.2568, -3.2152, -3.2924, -3.0607, -3.0200, -3.2737, -3.2149,\n         -2.9803, -2.9456, -3.2407, -2.9854, -3.1081, -3.1383, -3.2049, -2.9170,\n         -2.8585, -3.2674, -3.0591, -3.3000, -3.0030, -2.9572],\n        [-2.9476, -3.2550, -3.2159, -3.3175, -3.0739, -3.0295, -3.3148, -3.2178,\n         -3.0053, -2.9469, -3.2619, -2.9443, -3.1106, -3.1366, -3.1940, -2.8755,\n         -2.8385, -3.2532, -3.0663, -3.2923, -2.9768, -2.9688],\n        [-2.9617, -3.2504, -3.2153, -3.3313, -3.0895, -3.0339, -3.3380, -3.2208,\n         -3.0190, -2.9492, -3.2782, -2.9206, -3.1114, -3.1297, -3.1891, -2.8557,\n         -2.8223, -3.2518, -3.0697, -3.2895, -2.9603, -2.9754],\n        [-2.9689, -3.2453, -3.2145, -3.3390, -3.1024, -3.0357, -3.3504, -3.2236,\n         -3.0252, -2.9514, -3.2894, -2.9075, -3.1111, -3.1228, -3.1875, -2.8468,\n         -2.8114, -3.2541, -3.0717, -3.2878, -2.9502, -2.9794],\n        [-2.9726, -3.2409, -3.2136, -3.3434, -3.1115, -3.0362, -3.3568, -3.2257,\n         -3.0273, -2.9532, -3.2965, -2.9005, -3.1102, -3.1175, -3.1875, -2.8432,\n         -2.8047, -3.2567, -3.0729, -3.2865, -2.9441, -2.9819],\n        [-2.9745, -3.2376, -3.2131, -3.3459, -3.1175, -3.0363, -3.3600, -3.2272,\n         -3.0276, -2.9545, -3.3009, -2.8970, -3.1093, -3.1139, -3.1881, -2.8421,\n         -2.8009, -3.2587, -3.0736, -3.2855, -2.9406, -2.9835]],\n       grad_fn=<LogSoftmaxBackward>)\n---------\ntensor([[-2.8639, -3.2565, -3.2257, -3.2403, -3.0736, -3.0200, -3.1986, -3.2235,\n         -2.9437, -2.9466, -3.2215, -3.0639, -3.0910, -3.1103, -3.2302, -2.9912,\n         -2.8638, -3.3109, -3.0228, -3.3431, -3.0471, -2.9334],\n        [-2.9319, -3.2135, -3.2115, -3.3358, -3.0758, -3.0434, -3.2670, -3.2362,\n         -2.9525, -2.9517, -3.2452, -3.0258, -3.0538, -3.1128, -3.2230, -2.9411,\n         -2.8838, -3.2231, -3.0196, -3.3066, -2.9889, -2.9652],\n        [-2.9668, -3.2014, -3.2109, -3.3803, -3.0911, -3.0506, -3.3098, -3.2525,\n         -2.9735, -2.9526, -3.2746, -2.9983, -3.0307, -3.0989, -3.2236, -2.9122,\n         -2.8782, -3.1779, -3.0178, -3.2925, -2.9501, -2.9839],\n        [-2.9856, -3.1961, -3.2164, -3.4011, -3.1114, -3.0495, -3.3351, -3.2649,\n         -2.9947, -2.9520, -3.3004, -2.9818, -3.0191, -3.0785, -3.2235, -2.8994,\n         -2.8660, -3.1539, -3.0162, -3.2859, -2.9221, -2.9963],\n        [-2.9962, -3.1924, -3.2238, -3.4124, -3.1303, -3.0459, -3.3500, -3.2730,\n         -3.0115, -2.9512, -3.3190, -2.9726, -3.0137, -3.0591, -3.2223, -2.8949,\n         -2.8549, -3.1402, -3.0142, -3.2819, -2.9023, -3.0056],\n        [-3.0024, -3.1894, -3.2308, -3.4198, -3.1450, -3.0427, -3.3588, -3.2780,\n         -3.0233, -2.9507, -3.3311, -2.9675, -3.0110, -3.0439, -3.2207, -2.8937,\n         -2.8467, -3.1319, -3.0119, -3.2793, -2.8891, -3.0125],\n        [-3.0061, -3.1871, -3.2364, -3.4251, -3.1552, -3.0407, -3.3639, -3.2809,\n         -3.0310, -2.9508, -3.3382, -2.9646, -3.0096, -3.0331, -3.2195, -2.8935,\n         -2.8413, -3.1269, -3.0096, -3.2775, -2.8807, -3.0173]],\n       grad_fn=<LogSoftmaxBackward>)\n---------\ntensor([[-2.8823, -3.2449, -3.2329, -3.2524, -3.0831, -3.0034, -3.2215, -3.2132,\n         -2.9533, -2.9584, -3.2136, -3.0614, -3.1039, -3.1083, -3.2191, -2.9767,\n         -2.8500, -3.3097, -3.0364, -3.3165, -3.0317, -2.9403],\n        [-2.9430, -3.2037, -3.2122, -3.3453, -3.0834, -3.0385, -3.2820, -3.2293,\n         -2.9606, -2.9564, -3.2428, -3.0193, -3.0625, -3.1100, -3.2179, -2.9344,\n         -2.8771, -3.2223, -3.0253, -3.2933, -2.9805, -2.9669],\n        [-2.9733, -3.1925, -3.2023, -3.3853, -3.0909, -3.0523, -3.3235, -3.2510,\n         -2.9826, -2.9520, -3.2774, -2.9854, -3.0402, -3.1070, -3.2195, -2.8981,\n         -2.8716, -3.1774, -3.0219, -3.2875, -2.9527, -2.9872],\n        [-2.9881, -3.1888, -3.1998, -3.4004, -3.1052, -3.0539, -3.3486, -3.2699,\n         -3.0040, -2.9471, -3.3085, -2.9635, -3.0306, -3.0965, -3.2184, -2.8765,\n         -2.8578, -3.1553, -3.0217, -3.2865, -2.9340, -3.0018],\n        [-2.9953, -3.1863, -3.2014, -3.4063, -3.1212, -3.0502, -3.3635, -3.2833,\n         -3.0198, -2.9421, -3.3322, -2.9508, -3.0276, -3.0842, -3.2153, -2.8667,\n         -2.8448, -3.1443, -3.0222, -3.2856, -2.9210, -3.0126],\n        [-2.9986, -3.1837, -3.2047, -3.4096, -3.1352, -3.0455, -3.3723, -3.2918,\n         -3.0296, -2.9376, -3.3484, -2.9437, -3.0272, -3.0737, -3.2119, -2.8634,\n         -2.8352, -3.1384, -3.0224, -3.2840, -2.9124, -3.0207],\n        [-3.0001, -3.1812, -3.2081, -3.4123, -3.1458, -3.0415, -3.3775, -3.2968,\n         -3.0347, -2.9339, -3.3586, -2.9398, -3.0277, -3.0662, -3.2093, -2.8632,\n         -2.8290, -3.1350, -3.0225, -3.2819, -2.9074, -3.0264]],\n       grad_fn=<LogSoftmaxBackward>)\n---------\n","name":"stdout"}]},{"metadata":{"id":"Jln0YqmN75Lf","trusted":true},"cell_type":"code","source":"def code2seq(code,text_type):\n  if text_type=='ans':\n    Enc=ans_enc\n  else:\n    Enc=ques_enc\n  text=''\n  for c in code:\n    for key in Enc.keys():\n      if Enc[key]==c:\n        text=text+' '+key\n  return text\n\n","execution_count":19,"outputs":[]},{"metadata":{"id":"VWuynFIG8Ct8","outputId":"e3a38f32-697b-4ea5-c383-910859dca223","trusted":true},"cell_type":"code","source":"loss_function = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nepochs =50\nmodel.train()\nfor i in range(epochs):\n    Loss=0\n    correct=0\n    model.zero_grad()\n    for (input_text,output_text,q,a) in zip(Input,Output,question,answer):\n        #print(seq.shape)\n        \n        optimizer.zero_grad()\n        out=model(input_text)\n        #print(out.shape)\n        out_true=torch.argmax(output_text,dim=1)\n        #print(out_true)\n        y_pred=torch.argmax(out,dim=1) \n        ques=torch.argmax(input_text,dim=1)\n        #print('ques',code2seq(ques,'ques'))\n        #print('ans',code2seq(y_pred,'ans'))\n        #print(y_pred)\n        #print('actual ans',code2seq(out_true,'ans'))\n        if torch.equal(y_pred,out_true):\n          correct+=1\n        loss= loss_function(out,out_true)\n        #loss=Variable(single_loss,requires_grad=True)\n        loss.backward(retain_graph=True)\n        Loss+=loss.item()\n        #print(loss.item()/100)\n        #print('**********************')\n        optimizer.step()\n    print('epochs: {}---loss: {}--acc:{}'.format(i,Loss,correct/10))\n    ","execution_count":22,"outputs":[{"output_type":"stream","text":"epochs: 0---loss: 5.534053146839142--acc:0.1\nepochs: 1---loss: 4.364450842142105--acc:0.3\nepochs: 2---loss: 4.413447767496109--acc:0.4\nepochs: 3---loss: 3.734996497631073--acc:0.2\nepochs: 4---loss: 3.26523394882679--acc:0.3\nepochs: 5---loss: 3.0518191754817963--acc:0.2\nepochs: 6---loss: 2.8304440826177597--acc:0.4\nepochs: 7---loss: 2.6324123442173004--acc:0.6\nepochs: 8---loss: 2.4166130274534225--acc:0.6\nepochs: 9---loss: 2.233181908726692--acc:0.6\nepochs: 10---loss: 2.081766188144684--acc:0.6\nepochs: 11---loss: 1.949824720621109--acc:0.6\nepochs: 12---loss: 1.8280886709690094--acc:0.6\nepochs: 13---loss: 1.7152059897780418--acc:0.6\nepochs: 14---loss: 1.6110580414533615--acc:0.6\nepochs: 15---loss: 1.5586915388703346--acc:0.6\nepochs: 16---loss: 1.533575415611267--acc:0.6\nepochs: 17---loss: 1.4523241072893143--acc:0.6\nepochs: 18---loss: 1.3791361898183823--acc:0.6\nepochs: 19---loss: 1.2617467567324638--acc:0.6\nepochs: 20---loss: 1.1831544488668442--acc:0.6\nepochs: 21---loss: 1.1276766024529934--acc:0.6\nepochs: 22---loss: 1.075050462037325--acc:0.6\nepochs: 23---loss: 1.023210123181343--acc:0.6\nepochs: 24---loss: 0.9757692962884903--acc:0.6\nepochs: 25---loss: 0.933723971247673--acc:0.6\nepochs: 26---loss: 0.8954045102000237--acc:0.6\nepochs: 27---loss: 0.8598965033888817--acc:0.6\nepochs: 28---loss: 0.8270737677812576--acc:0.6\nepochs: 29---loss: 0.7966661751270294--acc:0.6\nepochs: 30---loss: 0.7682784870266914--acc:0.6\nepochs: 31---loss: 0.7413272820413113--acc:0.6\nepochs: 32---loss: 0.7151799127459526--acc:0.6\nepochs: 33---loss: 0.6889457814395428--acc:0.6\nepochs: 34---loss: 0.662214383482933--acc:0.6\nepochs: 35---loss: 0.6374508067965508--acc:0.7\nepochs: 36---loss: 0.6133406050503254--acc:0.7\nepochs: 37---loss: 0.5871463418006897--acc:0.7\nepochs: 38---loss: 0.5617588479071856--acc:0.7\nepochs: 39---loss: 0.539175508543849--acc:0.7\nepochs: 40---loss: 0.5164204780012369--acc:0.7\nepochs: 41---loss: 0.495908135548234--acc:0.7\nepochs: 42---loss: 0.4761887304484844--acc:0.7\nepochs: 43---loss: 0.45784595236182213--acc:0.7\nepochs: 44---loss: 0.44120551086962223--acc:0.7\nepochs: 45---loss: 0.4254879541695118--acc:0.7\nepochs: 46---loss: 0.4106607045978308--acc:0.7\nepochs: 47---loss: 0.39658662490546703--acc:0.7\nepochs: 48---loss: 0.38347875140607357--acc:0.7\nepochs: 49---loss: 0.371179960668087--acc:0.7\n","name":"stdout"}]},{"metadata":{"id":"dSNwa5KQ_WaT","trusted":true},"cell_type":"code","source":"for (input_text,output_text,q,a) in zip(Input,Output,question,answer):\n        #print(seq.shape)\n        out=model(input_text)\n        #print(out.shape)\n        out_true=torch.argmax(output_text,dim=1)\n        #print(out_true)\n        y_pred=torch.argmax(out,dim=1) \n        ques=torch.argmax(input_text,dim=1)\n        print('ques',code2seq(ques,'ques'))\n        print('ans',code2seq(y_pred,'ans'))","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"Seq_seq.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":4}